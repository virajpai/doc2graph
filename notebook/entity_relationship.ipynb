{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English NLP model\n",
    "nlp = spacy.load(\"en_core_web_lg\") #(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sentence\n",
    "sentence = \"Bill Gates founded Microsoft in the same year as Steve Jobs founded Apple.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the sentence with spaCy\n",
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract entities and relationships\n",
    "entities = [ent.text for ent in doc.ents]\n",
    "relationships = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bill Gates', 'Microsoft', 'the same year', 'Steve Jobs', 'Apple']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Bill\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Gates\n",
      "----------------------------------------------------------------------------------------------------\n",
      "founded\n",
      "ROOT VERB\n",
      "Sub: ['Gates']\n",
      "Obj: ['Microsoft']\n",
      "Rel: [('Gates', 'found', 'Microsoft')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Microsoft\n",
      "----------------------------------------------------------------------------------------------------\n",
      "in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "same\n",
      "----------------------------------------------------------------------------------------------------\n",
      "year\n",
      "----------------------------------------------------------------------------------------------------\n",
      "as\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Steve\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Jobs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "founded\n",
      "ROOT VERB\n",
      "Sub: ['Jobs']\n",
      "Obj: ['Apple']\n",
      "Rel: [('Gates', 'found', 'Microsoft'), ('Jobs', 'found', 'Apple')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Apple\n",
      "----------------------------------------------------------------------------------------------------\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"-\"*100)\n",
    "    print(token)\n",
    "    if token.pos_ == \"VERB\":\n",
    "        print(\"ROOT VERB\")\n",
    "        # Found the root verb (e.g., \"founded\")\n",
    "        subject = [child.text for child in token.children if child.dep_ == \"nsubj\"]\n",
    "        print(f\"Sub: {subject}\")\n",
    "        object_ = [child.text for child in token.children if child.dep_ == \"dobj\"]\n",
    "        print(f\"Obj: {object_}\")\n",
    "        if subject and object_:\n",
    "            relationships.append((subject[0], token.lemma_, object_[0]))\n",
    "            print(f\"Rel: {relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gates', 'found', 'Microsoft'), ('Jobs', 'found', 'Apple')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gates', 'found', 'Microsoft')\n",
      "('Jobs', 'found', 'Apple')\n"
     ]
    }
   ],
   "source": [
    "er = []\n",
    "# Print the entities and relationships\n",
    "for i, rel in enumerate(relationships):\n",
    "    en1 = \"\"\n",
    "    en2 = \"\"\n",
    "    relp = \"\"\n",
    "    \n",
    "    # print(f\"ER{i + 1}: {entity} --> {relationships[i][1]} --> {relationships[i][2]}\")\n",
    "    print(rel)\n",
    "    for r in rel:\n",
    "        entity = [e for e in entities if r in e]\n",
    "        if len(entity) >= 1:\n",
    "            entity = entity[0]\n",
    "            if en1 == \"\":\n",
    "                en1 = entity\n",
    "            else:\n",
    "                en2 = entity\n",
    "        else:\n",
    "            relp = r\n",
    "    er.append({\n",
    "        \"Entity1\": en1,\n",
    "        \"Relationship\": relp,\n",
    "        \"Entity2\": en2\n",
    "    })\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity1</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Entity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>found</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steve Jobs</td>\n",
       "      <td>found</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entity1 Relationship    Entity2\n",
       "0  Bill Gates        found  Microsoft\n",
       "1  Steve Jobs        found      Apple"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_er(sentence):\n",
    "    # Process the sentence with spaCy\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Extract entities and relationships\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    print(entities)\n",
    "    relationships = []\n",
    "\n",
    "    for token in doc:\n",
    "        # print(\"-\"*100)\n",
    "        print(token, \": \", token.pos_, \": \", token.dep_, \": \")\n",
    "        if token.dep_ == \"ROOT\" or token.pos_ == \"VERB\" or token.pos_ == \"AUX\":\n",
    "            # print(\"ROOT VERB\")\n",
    "            # Found the root verb (e.g., \"founded\")\n",
    "            subject = [child.text for child in token.children if child.dep_ == \"nsubj\"]\n",
    "            # print(f\"Sub: {subject}\")\n",
    "            object_ = [child.text for child in token.children if child.dep_ == \"dobj\"]\n",
    "            # print(f\"Obj: {object_}\")\n",
    "            if subject and object_:\n",
    "                relationships.append((subject[0], token.lemma_, object_[0]))\n",
    "                # print(f\"Rel: {relationships}\")\n",
    "    \n",
    "        # Look for relationships involving prepositional phrases\n",
    "        elif \"prep\" in token.dep_:\n",
    "            preposition = token.text\n",
    "            subject = token.head.text\n",
    "            object_ = [child.text for child in token.children if child.dep_ == \"pobj\"]\n",
    "            if object_:\n",
    "                relationships.append((subject, preposition, object_[0]))\n",
    "\n",
    "    print(relationships)\n",
    "\n",
    "    # Finalizing ER\n",
    "    er = []\n",
    "    # Print the entities and relationships\n",
    "    for i, rel in enumerate(relationships):\n",
    "        en1 = \"\"\n",
    "        en2 = \"\"\n",
    "        relp = \"\"\n",
    "        \n",
    "        # print(f\"ER{i + 1}: {entity} --> {relationships[i][1]} --> {relationships[i][2]}\")\n",
    "        # print(rel)\n",
    "        for r in rel:\n",
    "            entity = [e for e in entities if r in e]\n",
    "            if len(entity) >= 1:\n",
    "                entity = entity[0]\n",
    "                if en1 == \"\":\n",
    "                    en1 = entity\n",
    "                else:\n",
    "                    en2 = entity\n",
    "            else:\n",
    "                relp = r\n",
    "        er.append({\n",
    "            \"Entity1\": en1,\n",
    "            \"Relationship\": relp,\n",
    "            \"Entity2\": en2\n",
    "        })\n",
    "\n",
    "    return er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Bill Gates founded Microsoft in same year as Steve Jobs founded Apple.\",\n",
    "    \"Sachin Tendulkar was the greatest batsman of the World.\",\n",
    "    \"It's the job of CRMS to validate policy documents and process loan agreements\",\n",
    "    'Khuldabad: This ancient necropolis, also known as \"City of the Dead,\" boasts mystical tombs, mosques, and dargahs, offering a unique glimpse into Mughal and Deccan architecture.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bill Gates', 'Microsoft', 'same year', 'Steve Jobs', 'Apple']\n",
      "Bill :  PROPN :  compound : \n",
      "Gates :  PROPN :  nsubj : \n",
      "founded :  VERB :  ROOT : \n",
      "Microsoft :  PROPN :  dobj : \n",
      "in :  ADP :  prep : \n",
      "same :  ADJ :  amod : \n",
      "year :  NOUN :  pobj : \n",
      "as :  SCONJ :  mark : \n",
      "Steve :  PROPN :  compound : \n",
      "Jobs :  PROPN :  nsubj : \n",
      "founded :  VERB :  advcl : \n",
      "Apple :  PROPN :  dobj : \n",
      ". :  PUNCT :  punct : \n",
      "[('Gates', 'found', 'Microsoft'), ('founded', 'in', 'year'), ('Jobs', 'found', 'Apple')]\n",
      "[{'Entity1': 'Bill Gates', 'Relationship': 'found', 'Entity2': 'Microsoft'}, {'Entity1': 'same year', 'Relationship': 'in', 'Entity2': ''}, {'Entity1': 'Steve Jobs', 'Relationship': 'found', 'Entity2': 'Apple'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Sachin Tendulkar']\n",
      "Sachin :  PROPN :  compound : \n",
      "Tendulkar :  PROPN :  nsubj : \n",
      "was :  AUX :  ROOT : \n",
      "the :  DET :  det : \n",
      "greatest :  ADJ :  amod : \n",
      "batsman :  NOUN :  attr : \n",
      "of :  ADP :  prep : \n",
      "the :  DET :  det : \n",
      "World :  PROPN :  pobj : \n",
      ". :  PUNCT :  punct : \n",
      "[('batsman', 'of', 'World')]\n",
      "[{'Entity1': '', 'Relationship': 'World', 'Entity2': ''}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['CRMS']\n",
      "It :  PRON :  nsubj : \n",
      "'s :  AUX :  ROOT : \n",
      "the :  DET :  det : \n",
      "job :  NOUN :  attr : \n",
      "of :  ADP :  prep : \n",
      "CRMS :  PROPN :  pobj : \n",
      "to :  PART :  aux : \n",
      "validate :  VERB :  relcl : \n",
      "policy :  NOUN :  compound : \n",
      "documents :  NOUN :  dobj : \n",
      "and :  CCONJ :  cc : \n",
      "process :  NOUN :  compound : \n",
      "loan :  NOUN :  compound : \n",
      "agreements :  NOUN :  conj : \n",
      "[('job', 'of', 'CRMS')]\n",
      "[{'Entity1': 'CRMS', 'Relationship': 'of', 'Entity2': ''}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['mosques', 'Mughal', 'Deccan']\n",
      "Khuldabad :  PROPN :  nsubj : \n",
      ": :  PUNCT :  punct : \n",
      "This :  DET :  det : \n",
      "ancient :  ADJ :  amod : \n",
      "necropolis :  NOUN :  nsubj : \n",
      ", :  PUNCT :  punct : \n",
      "also :  ADV :  advmod : \n",
      "known :  VERB :  acl : \n",
      "as :  ADP :  prep : \n",
      "\" :  PUNCT :  punct : \n",
      "City :  PROPN :  pobj : \n",
      "of :  ADP :  prep : \n",
      "the :  DET :  det : \n",
      "Dead :  PROPN :  pobj : \n",
      ", :  PUNCT :  punct : \n",
      "\" :  PUNCT :  punct : \n",
      "boasts :  VERB :  ROOT : \n",
      "mystical :  ADJ :  amod : \n",
      "tombs :  NOUN :  dobj : \n",
      ", :  PUNCT :  punct : \n",
      "mosques :  NOUN :  conj : \n",
      ", :  PUNCT :  punct : \n",
      "and :  CCONJ :  cc : \n",
      "dargahs :  NOUN :  conj : \n",
      ", :  PUNCT :  punct : \n",
      "offering :  VERB :  advcl : \n",
      "a :  DET :  det : \n",
      "unique :  ADJ :  amod : \n",
      "glimpse :  NOUN :  dobj : \n",
      "into :  ADP :  prep : \n",
      "Mughal :  PROPN :  pobj : \n",
      "and :  CCONJ :  cc : \n",
      "Deccan :  ADJ :  amod : \n",
      "architecture :  NOUN :  conj : \n",
      ". :  PUNCT :  punct : \n",
      "[('known', 'as', 'City'), ('City', 'of', 'Dead'), ('Khuldabad', 'boast', 'tombs'), ('glimpse', 'into', 'Mughal')]\n",
      "[{'Entity1': '', 'Relationship': 'City', 'Entity2': ''}, {'Entity1': '', 'Relationship': 'Dead', 'Entity2': ''}, {'Entity1': '', 'Relationship': 'tombs', 'Entity2': ''}, {'Entity1': 'Mughal', 'Relationship': 'into', 'Entity2': ''}]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "entity_rels = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    er = get_all_er(sentence)\n",
    "    print(er)\n",
    "    print(\"-\"*100)\n",
    "    entity_rels.extend(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity1</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Entity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>found</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>same year</td>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve Jobs</td>\n",
       "      <td>found</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>world</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRMS</td>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>City</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Dead</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>tombs</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mughal</td>\n",
       "      <td>into</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entity1 Relationship    Entity2\n",
       "0  Bill Gates        found  Microsoft\n",
       "1   same year           in           \n",
       "2  Steve Jobs        found      Apple\n",
       "3                    world           \n",
       "4        CRMS           of           \n",
       "5                     City           \n",
       "6                     Dead           \n",
       "7                    tombs           \n",
       "8      Mughal         into           "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(entity_rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"All living things are made of cells.\", \n",
    "             \"Cells have organelles.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_patterns = [[{\"POS\":\"AUX\"}, {\"POS\":\"VERB\"}, \n",
    "                  {\"POS\":\"ADP\"}], \n",
    "                 [{\"POS\":\"AUX\"}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root_of_sentence(doc):\n",
    "    root_token = None\n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"ROOT\"):\n",
    "            root_token = token\n",
    "    return root_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_root(verb_phrase, root):\n",
    "    vp_start = verb_phrase.start\n",
    "    vp_end = verb_phrase.end\n",
    "    if (root.i >= vp_start and root.i <= vp_end):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_phrases(doc):\n",
    "    root = find_root_of_sentence(doc)\n",
    "    verb_phrases = textacy.extract.matches.token_matches(doc, \n",
    "                                                            verb_patterns)\n",
    "    new_vps = []\n",
    "    for verb_phrase in verb_phrases:\n",
    "        if (contains_root(verb_phrase, root)):\n",
    "            new_vps.append(verb_phrase)\n",
    "    return new_vps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longer_verb_phrase(verb_phrases):\n",
    "    longest_length = 0\n",
    "    longest_verb_phrase = None\n",
    "    for verb_phrase in verb_phrases:\n",
    "        if len(verb_phrase) > longest_length:\n",
    "            longest_verb_phrase = verb_phrase\n",
    "    return longest_verb_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_noun_phrase(verb_phrase, noun_phrases, side):\n",
    "    for noun_phrase in noun_phrases:\n",
    "        if (side == \"left\" and \\\n",
    "            noun_phrase.start < verb_phrase.start):\n",
    "            return noun_phrase\n",
    "        elif (side == \"right\" and \\\n",
    "              noun_phrase.start > verb_phrase.start):\n",
    "            return noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triplet(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    verb_phrases = get_verb_phrases(doc)\n",
    "    noun_phrases = doc.noun_chunks\n",
    "    verb_phrase = None\n",
    "    if (len(verb_phrases) > 1):\n",
    "        verb_phrase = \\\n",
    "        longer_verb_phrase(list(verb_phrases))\n",
    "    else:\n",
    "        verb_phrase = verb_phrases[0]\n",
    "    left_noun_phrase = find_noun_phrase(verb_phrase, \n",
    "                                        noun_phrases, \n",
    "                                        \"left\")\n",
    "    right_noun_phrase = find_noun_phrase(verb_phrase, \n",
    "                                         noun_phrases, \n",
    "                                         \"right\")\n",
    "    return (left_noun_phrase, verb_phrase, \n",
    "            right_noun_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m----> 2\u001b[0m     (left_np, vp, right_np) \u001b[38;5;241m=\u001b[39m \u001b[43mfind_triplet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(left_np, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, vp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, right_np)\n",
      "Cell \u001b[0;32mIn[84], line 10\u001b[0m, in \u001b[0;36mfind_triplet\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      7\u001b[0m     verb_phrase \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m      8\u001b[0m     longer_verb_phrase(\u001b[38;5;28mlist\u001b[39m(verb_phrases))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     verb_phrase \u001b[38;5;241m=\u001b[39m \u001b[43mverb_phrases\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m left_noun_phrase \u001b[38;5;241m=\u001b[39m find_noun_phrase(verb_phrase, \n\u001b[1;32m     12\u001b[0m                                     noun_phrases, \n\u001b[1;32m     13\u001b[0m                                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m right_noun_phrase \u001b[38;5;241m=\u001b[39m find_noun_phrase(verb_phrase, \n\u001b[1;32m     15\u001b[0m                                      noun_phrases, \n\u001b[1;32m     16\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    (left_np, vp, right_np) = find_triplet(sentence)\n",
    "    print(left_np, \"\\t\", vp, \"\\t\", right_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bill Gates founded Microsoft in same year as Steve Jobs founded Apple.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def extract_entities_and_relationships(sentence):\n",
    "\n",
    "    # Process the input sentence\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Extract named entities\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # Extract relationships between entities\n",
    "    relationships = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            # Extract the root of the sentence\n",
    "            root = token.text\n",
    "            for child in token.children:\n",
    "                # Extract relationships between the root and its children\n",
    "                relationships.append((root, child.text, child.dep_))\n",
    "\n",
    "    return entities, relationships\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('Apple Inc.', 'ORG'), ('Steve Jobs', 'PERSON'), ('Cupertino', 'GPE')]\n",
      "Relationships: [('founded', 'Inc.', 'nsubjpass'), ('founded', 'was', 'auxpass'), ('founded', 'by', 'agent'), ('founded', '.', 'punct')]\n"
     ]
    }
   ],
   "source": [
    "# Example sentence\n",
    "input_sentence = \"Apple Inc. was founded by Steve Jobs in Cupertino.\"\n",
    "\n",
    "# Extract entities and relationships\n",
    "entities, relationships = extract_entities_and_relationships(input_sentence)\n",
    "\n",
    "# Display the results\n",
    "print(\"Entities:\", entities)\n",
    "print(\"Relationships:\", relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
